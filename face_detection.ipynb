{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library Imports and Installing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q labelme bs4 tensorflow opencv-python matplotlib albumentations scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import albumentations as alb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Directory Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define character classes\n",
    "CHARACTER_CLASSES = {\n",
    "    \"Sheldon\": 0,\n",
    "    \"Leonard\": 1,\n",
    "    \"Penny\": 2,\n",
    "    \"Howard\": 3,\n",
    "    \"Raj\": 4,\n",
    "    \"Amy\": 5,\n",
    "    \"Bernadette\": 6\n",
    "}\n",
    "CHARACTER_NAMES = {v: k for k, v in CHARACTER_CLASSES.items()}  # Reverse mapping\n",
    "\n",
    "# Define paths\n",
    "IMG_DIR = \"data/images\"\n",
    "LABELS_DIR = \"data/labels\"\n",
    "TRAIN_IMAGES_DIR = os.path.join(\"data\", \"train\", \"images\")\n",
    "TRAIN_LABELS_DIR = os.path.join(\"data\", \"train\", \"labels\")\n",
    "VALIDATION_IMAGES_DIR = os.path.join(\"data\", \"validation\", \"images\")\n",
    "VALIDATION_LABELS_DIR = os.path.join(\"data\", \"validation\", \"labels\")\n",
    "TEST_IMAGES_DIR = os.path.join(\"data\", \"test\", \"images\")\n",
    "TEST_LABELS_DIR = os.path.join(\"data\", \"test\", \"labels\")\n",
    "\n",
    "\n",
    "# Define agumentation paths\n",
    "AUG_DATA_DIR = \"aug_data\"\n",
    "TRAIN_AUG_IMAGES_DIR = os.path.join(AUG_DATA_DIR, \"train\", \"images\")\n",
    "TRAIN_AUG_LABELS_DIR = os.path.join(AUG_DATA_DIR, \"train\", \"labels\")\n",
    "VALIDATION_AUG_IMAGES_DIR = os.path.join(AUG_DATA_DIR, \"validation\", \"images\")\n",
    "VALIDATION_AUG_LABELS_DIR = os.path.join(AUG_DATA_DIR, \"validation\", \"labels\")\n",
    "TEST_AUG_IMAGES_DIR = os.path.join(AUG_DATA_DIR, \"test\", \"images\")\n",
    "TEST_AUG_LABELS_DIR = os.path.join(AUG_DATA_DIR, \"test\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure necessary directories exist\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(LABELS_DIR, exist_ok=True)\n",
    "os.makedirs(TRAIN_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(TRAIN_LABELS_DIR, exist_ok=True)\n",
    "os.makedirs(VALIDATION_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(VALIDATION_LABELS_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_LABELS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "os.makedirs(AUG_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(TRAIN_AUG_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(TRAIN_AUG_LABELS_DIR, exist_ok=True)\n",
    "os.makedirs(VALIDATION_AUG_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(VALIDATION_AUG_LABELS_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_AUG_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_AUG_LABELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Setting up functions and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs for each character\n",
    "CHARACTER_URLS = {\n",
    "    \"Sheldon\": \"https://www.imdb.com/title/tt0898266/mediaindex/?relatedNames=nm1433588\",\n",
    "    \"Leonard\": \"https://www.imdb.com/title/tt0898266/mediaindex/?relatedNames=nm0301959\",\n",
    "    \"Penny\": \"https://www.imdb.com/title/tt0898266/mediaindex/?relatedNames=nm0192505\",\n",
    "    \"Howard\": \"https://www.imdb.com/title/tt0898266/mediaindex/?relatedNames=nm0374865\",\n",
    "    \"Raj\": \"https://www.imdb.com/title/tt0898266/mediaindex/?relatedNames=nm2471798\",\n",
    "    \"Amy\": \"https://www.imdb.com/title/tt0898266/mediaindex/?relatedNames=nm0080524\",\n",
    "    \"Bernadette\": \"https://www.imdb.com/title/tt0898266/mediaindex/?relatedNames=nm1851981\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers to simulate a browser\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_directory(base_dir):\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(image_urls, save_path, limit=30, prefix=\"\"):\n",
    "    for i, url in enumerate(image_urls[:limit]):\n",
    "        try:\n",
    "            unique_filename = f\"{prefix}_{uuid.uuid4()}.jpg\"\n",
    "            response = requests.get(url, headers=HEADERS, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                with open(os.path.join(save_path, unique_filename), \"wb\") as file:\n",
    "                    for chunk in response.iter_content(1024):\n",
    "                        file.write(chunk)\n",
    "            else:\n",
    "                print(f\"Error accessing image {i + 1}: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading image {i + 1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_urls(imdb_url):\n",
    "    try:\n",
    "        response = requests.get(imdb_url, headers=HEADERS)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        images = soup.find_all('img')\n",
    "        image_urls = [\n",
    "            img['src']\n",
    "            for img in images\n",
    "            if 'src' in img.attrs and 'media' in img['src']\n",
    "        ]\n",
    "        return image_urls\n",
    "    except Exception as e:\n",
    "        print(f\"Error collecting URLs from {imdb_url}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_images():\n",
    "    create_base_directory(IMG_DIR)\n",
    "    for character, url in CHARACTER_URLS.items():\n",
    "        print(f\"Downloading images for {character}...\")\n",
    "        image_urls = get_image_urls(url)\n",
    "        if not image_urls:\n",
    "            print(f\"No images found for {character}.\")\n",
    "            continue\n",
    "        download_images(image_urls, IMG_DIR, prefix=character)\n",
    "        print(f\"{character}: Images downloaded successfully!\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Collecting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Annotate Images with LabelMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-31 18:11:03.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelme.config\u001b[0m:\u001b[36mget_config\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mLoading config file from: C:\\Users\\welli\\.labelmerc\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Partition Unaugmented Data into Train, Validation, and Test Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(img_dir, labels_dir, train_dir, val_dir, test_dir):\n",
    "    \"\"\"\n",
    "    Split dataset into training, validation, and test directories for both images and labels.\n",
    "\n",
    "    Args:\n",
    "        img_dir (str): Path to the directory containing images.\n",
    "        labels_dir (str): Path to the directory containing corresponding labels.\n",
    "        train_dir (str): Path to the directory to store training images and labels.\n",
    "        val_dir (str): Path to the directory to store validation images and labels.\n",
    "        test_dir (str): Path to the directory to store test images and labels.\n",
    "    \"\"\"\n",
    "    # List all image files\n",
    "    images = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]\n",
    "\n",
    "    # Split data into training (70%), validation (15%), and test (15%)\n",
    "    train_images, temp_images = train_test_split(images, test_size=0.3, random_state=42)\n",
    "    val_images, test_images = train_test_split(temp_images, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Helper function to move images and their corresponding labels\n",
    "    def move_files(file_list, src_dir, dest_img_dir, dest_label_dir):\n",
    "        for img in file_list:\n",
    "            # Move image file\n",
    "            os.rename(os.path.join(src_dir, img), os.path.join(dest_img_dir, img))\n",
    "            # Derive corresponding label filename\n",
    "            label_file = img.replace('.jpg', '.json')\n",
    "            # Move label file if it exists\n",
    "            if os.path.exists(os.path.join(labels_dir, label_file)):\n",
    "                os.rename(\n",
    "                    os.path.join(labels_dir, label_file),\n",
    "                    os.path.join(dest_label_dir, label_file)\n",
    "                )\n",
    "\n",
    "    # Move training data\n",
    "    move_files(train_images, img_dir, train_dir, train_dir.replace('images', 'labels'))\n",
    "\n",
    "    # Move validation data\n",
    "    move_files(val_images, img_dir, val_dir, val_dir.replace('images', 'labels'))\n",
    "\n",
    "    # Move test data\n",
    "    move_files(test_images, img_dir, test_dir, test_dir.replace('images', 'labels'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the split\n",
    "split_data(IMG_DIR, LABELS_DIR, TRAIN_IMAGES_DIR, VALIDATION_IMAGES_DIR, TEST_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Augmentation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation pipeline with bounding box handling\n",
    "augmentor = alb.Compose([\n",
    "    alb.RandomCrop(width=450, height=450), \n",
    "    alb.HorizontalFlip(p=0.5), \n",
    "    alb.RandomBrightnessContrast(p=0.2),\n",
    "    alb.RandomGamma(p=0.2), \n",
    "    alb.RGBShift(p=0.2), \n",
    "    alb.VerticalFlip(p=0.5)], \n",
    "    bbox_params=alb.BboxParams(format='albumentations', label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test augmentation with a single image\n",
    "def test_augmentation(image_path, label_path):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    # Load label\n",
    "    with open(label_path, 'r') as f:\n",
    "        label = json.load(f)\n",
    "    coords = label['shapes'][0]['points']\n",
    "    bbox = [coords[0][0] / w, coords[0][1] / h, coords[1][0] / w, coords[1][1] / h]  # Normalize bbox\n",
    "\n",
    "    # Apply augmentation\n",
    "    augmented = augmentor(image=img, bboxes=[bbox], class_labels=['face'])\n",
    "\n",
    "    # Visualize augmented image and bbox\n",
    "    aug_img = augmented['image']\n",
    "    aug_bbox = augmented['bboxes'][0]\n",
    "    start_point = (int(aug_bbox[0] * aug_img.shape[1]), int(aug_bbox[1] * aug_img.shape[0]))\n",
    "    end_point = (int(aug_bbox[2] * aug_img.shape[1]), int(aug_bbox[3] * aug_img.shape[0]))\n",
    "    cv2.rectangle(aug_img, start_point, end_point, (255, 0, 0), 2)\n",
    "    cv2.imshow(\"Augmented Image\", aug_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Viewing Dataset, and Build Image Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Limit GPU Memory Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load Image into TF Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.data.Dataset.list_files('..\\\\data\\\\face-detection\\\\images\\\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'..\\\\data\\\\face-detection\\\\images\\\\Leonard_b015552d-40ce-4dd2-9f82-84b34756afd7.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 69,  74,  70],\n",
       "        [ 70,  75,  71],\n",
       "        [ 71,  76,  72],\n",
       "        ...,\n",
       "        [211, 202, 187],\n",
       "        [200, 191, 176],\n",
       "        [193, 184, 169]],\n",
       "\n",
       "       [[ 69,  74,  70],\n",
       "        [ 70,  75,  71],\n",
       "        [ 71,  76,  72],\n",
       "        ...,\n",
       "        [217, 208, 193],\n",
       "        [206, 197, 182],\n",
       "        [201, 192, 177]],\n",
       "\n",
       "       [[ 69,  74,  70],\n",
       "        [ 70,  75,  71],\n",
       "        [ 71,  76,  72],\n",
       "        ...,\n",
       "        [225, 213, 197],\n",
       "        [218, 206, 190],\n",
       "        [214, 202, 186]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[150, 149, 154],\n",
       "        [158, 157, 162],\n",
       "        [157, 156, 161],\n",
       "        ...,\n",
       "        [ 54,  73, 106],\n",
       "        [ 54,  73, 106],\n",
       "        [ 54,  73, 106]],\n",
       "\n",
       "       [[134, 133, 138],\n",
       "        [164, 163, 168],\n",
       "        [159, 158, 163],\n",
       "        ...,\n",
       "        [ 57,  73, 107],\n",
       "        [ 57,  73, 107],\n",
       "        [ 57,  73, 107]],\n",
       "\n",
       "       [[132, 131, 136],\n",
       "        [175, 174, 179],\n",
       "        [162, 161, 166],\n",
       "        ...,\n",
       "        [ 58,  74, 108],\n",
       "        [ 58,  74, 108],\n",
       "        [ 58,  74, 108]]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.MapDataset"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 View Raw Images with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = images.batch(4).as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [604,820,3], [batch]: [547,820,3] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_images \u001b[38;5;241m=\u001b[39m \u001b[43mimage_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\welli\\anaconda3\\envs\\facedet\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4481\u001b[0m, in \u001b[0;36m_NumpyIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 4481\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\welli\\anaconda3\\envs\\facedet\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4478\u001b[0m, in \u001b[0;36m_NumpyIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4475\u001b[0m     numpy\u001b[38;5;241m.\u001b[39msetflags(write\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   4476\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m numpy\n\u001b[1;32m-> 4478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mmap_structure(to_numpy, \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\welli\\anaconda3\\envs\\facedet\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\welli\\anaconda3\\envs\\facedet\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\welli\\anaconda3\\envs\\facedet\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3014\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3016\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3018\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\welli\\anaconda3\\envs\\facedet\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [604,820,3], [batch]: [547,820,3] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "plot_images = image_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, image in enumerate(plot_images):\n",
    "    ax[idx].imshow(image) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facedet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
